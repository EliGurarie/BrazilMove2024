---
title: 'Home Range Analyses: Kernel Density Estimates'
author: "Nicki Barbour and Elie Gurarie"
subtitle: "[Brazil Move 2024 - UFMS - Campo Grande](https://eligurarie.github.io/BrazilMove2024)"
date: "May 23, 2024"
output:
  html_document:
    toc: true
    toc_float: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, 
                      cache = TRUE)
```

# Goal

> To estimate home ranges with Kernel Density Estimates. 

Packages:

```{r, cache = FALSE}
library(ggplot2)
library(plyr)
library(sf)
library(adehabitatHR)
library(mapview)
```


# Selecting some animals

```{r loadData, echo = -1}
setwd("../")
load("./data/elk_processed.rda")
head(elk_gps)
```

Same 3 individuals as in the [MCP lab](HomeRanges_KDE.html):

```{r SelectResidentElk}
elk_res <- elk_gps |>
  subset(id %in% c("YL80", "YL91", "YL94")) |>
  mutate(id = droplevels(id))

elk_res_sf <- elk_res |> 
  st_as_sf(coords = c("lon","lat"), crs = 4326) |> 
  st_transform(32611) 

elk_res <- cbind(elk_res, st_coordinates(elk_res_sf))
```
 
# Kernel Density Estimates

Kernel density estimation (KDE) is a slightly more complex method used to calculate homerange areas, also using the `adehabitatHR` package. As defined by this package, it essentially defines the KDE homerange as the "*minimum area in which an animal has some specified probability of being located*".

KDE applies a user-specified function to input points/locations in order to predict the probability of occurrence or the "utilization distribution", within each pixel of a user-specified grid. The choice of resolution for this grid can have a trade-off, with a finer resolution being more memory-intensive to calculate. The choice of this resolution should be informed by the resolution of the input data.

A commonly used function for KDE (and the default for the adehabitatHR package function, `kernelUD`) is the "bivariate normal kernel". This function takes a set of individual observations, a parameter for the number of observations, and *importantly*, a user-specified parameter for the smoothing factor, *h* (also called the "bandwidth"). The choice of the value for this *h* parameter can significantly impact results, with a larger *h* resulting in more smoothing or a larger distance over which a data point influences the utlization distribution. The adehabitatHR package uses the "reference bandwidth" as a default with its `kernelUD` function but additional options exist (e.g., the "least-square cross validation method" or a user-chosen value).

Users can also specify the percentage of density to use for homerange estimation (usually 50-95%), within the `getverticeshr` function, which calculates the homerange area using the estimated utilization distribution from the `kernelUD` function.

Similar to the `mcp` function, the `kernelUD` and `getverticeshr` functions are applied to one individual at a time. To apply to all individuals at once, we can write our own function. The function takes an individual sf object, a user-specified grid, and a user-specified percent. It then converts the data into "SpatialPoints" format and applies the `kernelUD` and `getverticeshr` to get the estimated homerange contour. The contour is then converted back to an sf object (as a POLYGON) and the area of the polygon is calculated using the `st_area`. This area is added as a column to our output homerange polygon object.

## Compute and plot KDE

We'll do it here for one animal:

```{r PickAnElk}
myelk_sf <- elk_res_sf |> subset(id == "YL80")
myelk_sp <- myelk_sf |>  as_Spatial() 
myelk_kernelud <- kernelUD(myelk_sp, grid = 200)
```

This object estimates a whole density function, which looks like this: 

```{r}
plot(myelk_kernelud)
```

You can convert this to a `raster`, which is spatially referenced:

```{r}
require(raster)
my_kernel <- raster(myelk_kernelud)
my_kernel
plot(my_kernel)
```

And you can even use this in a mapview:

```{r mapviewKernel, cache = FALSE}
mapview(my_kernel)
```

Contours can be helpful:


```{r contourPlotKernel}
plot(my_kernel)
contour(my_kernel, add = TRUE)
```

Or, for fun, a 3D plot:

```{r PerspPlotKernel}
persp(my_kernel, border = NA, shade = TRUE)
```



## Derived quantities

From this, you can calculate a few metrics.  For example, if you want the border of a 95% kernel (somewhat similar to what the MCP returns):
 
```{r getKDEpolygon}
myelk_kde_poly <- getverticeshr(myelk_kernelud, percent = 95) |>
  st_as_sf()
myelk_kde_poly
```

Note, that you can easily obtain the area of this polygon

```{r getArea}
st_area(myelk_kde_poly)
```

And map this:

```{r mapview2, cache =FALSE}
mapview(myelk_kde_poly) + mapview(myelk_sf)
```


We can also write a function that obtains all this information:

```{r getKernelPolyFunction}
getKernelPoly <- function(sf, percent = 95, idcol = "id", ...){
  sp <- sf |> mutate(id = droplevels(get(id))) 
  as_Spatial(sp[,"id"], cast = TRUE, IDs = "id") |> kernelUD(...) |>
  getverticeshr(percent = 95) |> 
  st_as_sf()
}
```

You can use this to compare different parameters, like kernel choice (remember the differenve between the `bivnorm` and `epa` kernels): 


```{r ComparingKernels}
kde_poly_norm <- getKernelPoly(elk_sf |> subset(id == "YL91"), kern = "bivnorm") 
kde_poly_epa <- getKernelPoly(elk_sf |> subset(id == "YL91"), kern = "epa") 

kde_compare_kernels <- rbind(
  kde_poly_norm |> mutate(type = "Bivariate Normal"),
  kde_poly_epa |> mutate(type = "Epanechnikov"))

ggplot(kde_compare_kernels) + geom_sf(aes(fill = type), alpha = .5) + 
    geom_sf(data = elk_sf |> subset(id == "YL91"), alpha = .2, size = 1)
```



Or ... you cam compute all of the kerners for a bunch of individuals(!)

```{r computeAllMCPs}
MCP_allElks <- getKernelPoly(elk_sf |> st_transform(32611), kern = "epa") 
```
 
All the MCP's plotted:
 
```{r mapAllMCPs}
ggplot(MCP_allElks) + 
  geom_sf(aes(fill = id, color = id), alpha = .2)
```

Now we can get some real statistics:

```{r AndSummarize}
MCP_allElks
summary(MCP_allElks$area)
```

Amazing variation in the kernel estimates!



# Kernel overlaps

[Fieberg and Kochanny 2010](https://wildlife.onlinelibrary.wiley.com/doi/abs/10.2193/0022-541X(2005)69[1346:QHOTIO]2.0.CO;2) argue convincingly that if you are esimating overlap between multiple organisms, you should leverage the power of the whole kernel density. 

Let's get two kernel densities:


```{r computeTwoKernels}
elk1 <- elk_res_sf |> subset(id == "YL80")
elk2 <- elk_res_sf |> subset(id == "YL94")

kernel1 <- elk1 |>  as_Spatial() |>  kernelUD(grid = 200)
kernel2 <- elk2 |>  as_Spatial() |>  kernelUD(grid = 200)
```

Plotting both kernels as contours:

```{r Countour2Kernels}
contour(kernel1, 
        xlim = c(590e3, 610e3), ylim = c(5720e3, 5745e3), 
        col = "blue")
 contour(kernel2, add = TRUE, col = "red")
axis(1); axis(2)
```

To compute overlap, you just have to convert your `sf` list of objects into a `SpatialPointsDataFrame` - but - importantly, identify `id` as the ID column. 

The `VI` is the "volume overlap" measure.  

```{r}
threeElks_sp <- as_Spatial(elk_res_sf[,"id"], cast = TRUE, IDs = "id")
kerneloverlap(threeElks_sp, method = "VI", kern = "epa")
```

Note how high that overlap is! 



